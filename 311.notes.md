#CSCI 311 Q1 Review
---
##Week 1
1. http://www.ecst.csuchico.edu/~judyc/1516S-csci311/notes/01-intro.html -> _Algorithms & Efficiency_
2. Read Cormen 1.1-1.2

##Week 2
1. http://www.ecst.csuchico.edu/~judyc/1516S-csci311/notes/02-insertionSort.html -> _Insertion Sort_
2. http://www.ecst.csuchico.edu/~judyc/1516S-csci311/notes/05-analysis.html -> _Analysis_
3. Read Cormen 2.3, 3.1 and 3.2

##week 3
1. http://www.ecst.csuchico.edu/~judyc/1516S-csci311/notes/06-asymptotic.html -> _Merge Sort_
2. Cormen 7.4??

---

##Notes from lecture, week 1

###Terminology
* __algorithm:__ well-defined computational procedure that takes some value, or set of values, as input and produces some value, or set of values as output.
* __problem statement:__ specifies in general terms the desired input/output relationship.
* __instance:__ the input (satisfying whatever constraints are imposed in the problem statement) needed to compute a solution to the problem
* __correctness:__ for every input instance, the algorithm halts with the correct output.
* __data structure:__ a way to store and organize data in order to facilitate access and modifications.

###Example
* a problem statement (sorting)

		Input: A sequence of n numbers {a[1], a[2],...,a[n]}
		Output: A permutation (reordering) {a'[1], a'[2],...,a'[n]} such that a'[1] <= a'[2] <= ... <=a'[n].
* An instance of the problem

		[31, 41, 59, 26, 41, 58]

* The solution

		{26, 31, 41, 41, 58, 59}

###Effiency
Growth  | n=100 | n=1000 | n=1x10^6| n=1x10^9|
------------- | ------------- |------------- |------------- |-------------
f(n)=lg^n  | ≈6.644		  | ≈9.966       | ≈19.932      | ≈29.897
f(n)=n        | ≈100          | ≈1000        | ≈1000000     | ≈1000000000
f(n)=n^2      | ≈10000        | ≈1000000     | ≈1 X 10^12   | ≈1 X 10^18
f(n)=n^3      | ≈1000000      | 1000000000   | ≈1 X 10^18   | ≈1 X 10^27
f(n)=2^n      | ≈1.26... x 10^30        | ≈blah       | ≈blah      | ≈blah
f(n)=n!       | ≈9.33 X 10^157        | ≈stupidBig       | ≈galaxySpanning       | ≈mindAltering


##Notes from Cormen, week 1:


###1.1 & 1.2

_What are algorithms? Why is the study of algorithms worthwhile? What is the role of algorithms relative to other technologies used in computers?_

__Algorithm:__ Any well-defined computational procedure that takes some value, or set of values, as input and produces some value, or set of values, as output. i.e. An algorithm is a sequence of computation steps that transform the input into the output

__Merge sort vs Insertion sort__:
For the sorting of 100 million numbers, insertion sort takes more than 23 days, while merge sort takes under four hours. In general, as the problem size increases, so does the relative advantage of merge sort.

__Example problems__:

__1.2-2__
Suppose we are comparing implementations of insertion sort and merge sort on the same machine, For inputs of size n, insertion sort runs in 8n^2 steps, while merge sort runs in 64nlgn steps. For which values of n does insertion sort beat merge sort?

__1.2-3__
What is the smallest value of n such that an algorithm whose running time is 100n^2 runs faster than an algorithm whose running time is 2^n on the same machine?


##Notes from lecture, week 2

###Terminology

* __insertion sort:__ an efficient algorithm for sorting a small number of elements by inserting each in sorted order, shifting elements where necessary.
* __keys:__ the numbers being sorted are also called keys
* __pseudocode:__ whatever expressive method is most clear and concise to specify a given algorithm - could be English, could be close to a programming language syntax, could throw in a math equation even.
* __loop invariant:__ a property that holds true immediately before and immediately after each iteration of a loop - used to argue correctness.

###Insertion Sort Algorithm

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.1-01.jpg)

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.1-02.jpg)

_note_

* stepping through insertion sort on A = <5, 2, 4, 6, 1, 3>
* array indices on top (they start at 1!)
* black is the key
* gray are elements compared with the key
* arrows show elements

###Showing Algorithm Correctness Using a Loop Invariant

a loop invariant is a property that holds true immediately before and immediately after each iteration of a loop - note that this says nothing about its truth or falsity part way through an iteration.

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.1-03.jpg)

_This is an example of how to use a loop invariant to argue correctness of the insertion sort algorithm:_

__Statement:__ the loop invariant - the subarray to the left of j is always in sorted order

* initialization
 * before the first loop iteration, j = 2
 * the subarray is just one element, A[1], which is sorted
* maintenance
 * a loop iteration shifts elements left of j, A[j-1], A[j-2],..., to the right one position until it finds the proper position for A[j] and inserts it.
 * when j is incremented to j+1, A[1...j-1] is in sorted order
* termination
 * the loop terminates when j > A.length = n
 * so j = n+1 when the loop terminates
 * so A[0..j-1] = A[1..n] (the entire array!) is in sorted order
 
_Correctness proven_

###Analysis of Insertion Sort

typically we are looking at computational time, although you can also analyze other things. Computational time taken depends on the input, both size and content (the order matters). 

We will define running time of a program as a function of the size of the input. definition of input size depends on the problem: number of inputs, number of bits, number of nodes, etc. 

Running time is based on the number of steps the algorithm takes - we assume each line of pseudocode executed takes constant time 

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.2-01.jpg)

In the nested loop, tj indicates the number of times the given line executes for loop iteration j, you can add these up.

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.2-02.jpg)

In the best case we assume that the array is already sorted, then tj = 1 during every iteration of the loop.

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.2-03.jpg)

###Order of Growth (Big O)

we are typically most interested in the worst case analysis, it gives us an upper bound as the algorithm will never perform worse than this. Some algorithms frequently encounter their worst case input, often the average case is just as bad as the worst case. It is more complicated to derive a formula for the average case, what is an average input?

in addition, we are only interested in the order of the first term of the T(n). We are generally interested in knowing what happens as n gets large, the lower order terms become insignificant.

The worst case running time for insertion sort is O(n^2) - "order n squared". We consider one algorithm to be more efficient than another if its worst case running time has a lower order of growth. __O(1)__ is more efficient than __O(n)__ is more efficient than __O(n log2 n)__ is more efficient than __O(n^2)__ is more efficient than __O(n^3)__ etc.


![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/order.png)


![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/ordergraph.png)



###Practice

illustrate insertion sort on A = < a1, a2, a3, a4, a5, a6 > (randomly select six integers for the ai)

write down the entire array after every modification to the array, keep track of changes to key as well 


##Notes from Cormen, week 2:
__2.1 & 2.2__

__insertion sort:__ The algorithm sorts the input numbers __in place__; it rearranges the numbers within the array A, with at most a constant number of them stored outside the array at any time. The input array A contains the sorted output sequence when the insertion sort procedure is finished.

__Exercises__

__2.1-:__ Illustrate the operation of insertion sort on the array A = {31, 41, 59, 26, 41, 58}

__2.1-2:__ rewrite the insertion sort procedure to sort into non-increasing instead of non-decreasing order.

__2.2-1:__ Express the function n^3/1000 - 100n^2 -100n + 3 in terms of Θ-notation.


##Notes from lecture, week 3

###Terminology
* __input size:__ How many of a specific type of input - usually designated 'n' - type depends on algorithm.
* __running time:__ The number of primitive steps taken in the execution of an algorithm.
* __worst case running time:__ The worst running time of an algorithm on any input of size n.
* __order of growth:__ the leading term of the running time formula ignoring the coefficient - a measure of the growth of running time as the input size grows

###Divide and Conquer Algorithm

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.3-01.jpg)


###Merge Sort

A is the entire sequence to be sorted. P, q, and r are indices - reminder: indexing starts at 1 in this pseudocode. A[p..r] is the subsequence to be sorted

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.3-02.jpg)

The merging of two sorted sequences is the key part of the algorithm 

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.3-03.jpg)

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.3-04.jpg)

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.3-09.jpg)

###Correctness of Merge Sort

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.3-05.jpg)

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.3-06.jpg)

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.3-07.jpg)

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.3-08.jpg)

###Analysis of Merge Sort

__Terminology__

* __recursive algorithm:__ To solve a given problem, the algorithm calls itself recursively one or more times to deal with closely related subproblems 
* __recurrence equation:__ Describes the running time on a problem of size n in terms of the running time on smaller inputs 
* __recursion tree:__ A diagram that looks like an upside-down tree showing each level of recursive calls - can be used to visualize running time 

###Analysis of Divide and Conquer Algorithms

This approach works on many recursive (like divide and conquer) algorithms. A recursive algorithm is one that calls itself we can define its run time using a recurrence equation define the run time on input of size n in terms of the run time on smaller inputs we have mathematical tools to solve recurrences.

let T(n) be the run time on input of size n. If n is small the solution will take constant time. We divide the problem into subproblems of size n/b (a=b=2 in merge sort). It takes T(n/b) to solve one subproblem and aT(n/b) to solve all of them. Suppose it takes D(n) time to divide the problem and C(n) time to combine solutions then here is the recurrence equation

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.3-10.jpg)

If we apply this algorithm to merge sort specifically we get:

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch02/2.3-12.jpg)

* merge sort is a recursive algorithm
* we define T(n) as a recurrence equation
* assume n is a power of 2 and the divide step results in two subsequences of size n/2
* divide: divide step takes constant time, so D(n) = θ(1)
* conquer: recursive solve of two subproblems takes 2T(n/2)
* combine: the merge step is linear in n or C(n) = θ(n)
* D(n) + C(n) = θ(1) + θ(n) = θ(n)
* This simplifies to θ(n lg n) for the worst case

##Asymptotic Notation

 the primary use is to describe the running times of algorithms
can also be used to characterize functions of other things like memory requirements
asymptotic notation is a way to describe the behavior of functions in the limit
we’re studying asymptotic efficiency
describes the growth of functions as a function of the size of the problem
we focus on what is important by abstracting away low-order terms and constant factors
all of the functions are assumed to be asymptotically positive
gives us a way to compare “efficiency” of functions: 

Cormen:
When we look at input sizes large enough to make only the order of growth of the running time relevant, we are studying the asymptotic efficiency of algorithms. Usually an algorithm that is asymptotically more efficient will be the best choice for all but very small inputs.

Ο ≈ ≤ big Omicron or "big O" notation
Ω ≈ ≥ big Omega
Θ ≈ = big Theta
ο ≈ > little omicron or "little o" notation
ω ≈ < little omega


big Omicron  |big Omega | big Theta | little omicron  | little omega|
:-------------:| :---------:|:-----------:|:-----------------:|:-------------:|
Ο ≈ ≤ | Ω ≈ ≥ | Θ ≈ = 	| ο ≈ > |ω ≈ <|  
upper bound (includes worst case)  | lower bound (includes best case) |  upper and lower bound (is in between two other cases, i.e. tight bound) | less than (but not best case) | greater than (but not worst case)



![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch03/big-o.jpg)

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch03/big-omega.jpg)

![Alt text](http://www.ecst.csuchico.edu/~judyc/1516S-csci311/images/ch03/theta.jpg)


##Accumulated Vocab

* __algorithm:__ well-defined computational procedure that takes some value, or set of values, as input and produces some value, or set of values as output.
* __problem statement:__ specifies in general terms the desired input/output relationship.
* __instance:__ the input (satisfying whatever constraints are imposed in the problem statement) needed to compute a solution to the problem
* __correctness:__ for every input instance, the algorithm halts with the correct output.
* __data structure:__ a way to store and organize data in order to facilitate access and modifications.

* __insertion sort:__ an efficient algorithm for sorting a small number of elements by inserting each in sorted order, shifting elements where necessary.
* __keys:__ the numbers being sorted are also called keys
* __pseudocode:__ whatever expressive method is most clear and concise to specify a given algorithm - could be English, could be close to a programming language syntax, could throw in a math equation even.
* __loop invariant:__ a property that holds true immediately before and immediately after each iteration of a loop - used to argue correctness.


* __input size:__ How many of a specific type of input - usually designated 'n' - type depends on algorithm.
* __running time:__ The number of primitive steps taken in the execution of an algorithm.
* __worst case running time:__ The worst running time of an algorithm on any input of size n.
* __order of growth:__ the leading term of the running time formula ignoring the coefficient - a measure of the growth of running time as the input size grows

* __recursive algorithm:__ To solve a given problem, the algorithm calls itself recursively one or more times to deal with closely related subproblems 
* __recurrence equation:__ Describes the running time on a problem of size n in terms of the running time on smaller inputs 
* __recursion tree:__ A diagram that looks like an upside-down tree showing each level of recursive calls - can be used to visualize running time 